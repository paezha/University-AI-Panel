

@article{angwin_opinion_2024,
	chapter = {Opinion},
	title = {{Press} {Pause} on the {Silicon} {Valley} {Hype} {Machine}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2024/05/15/opinion/artificial-intelligence-ai-openai-chatgpt-overrated-hype.html},
	abstract = {A.I. is looking less like an all-powerful being and more like an unreliable intern.},
	language = {en-US},
	urldate = {2024-05-19},
	journal = {The New York Times},
	author = {Angwin, Julia},
	month = may,
	year = {2024},
	keywords = {Altman, Samuel H, Artificial Intelligence, ChatGPT, Computers and the Internet, Labor and Jobs, OpenAI Labs, Research},
}

@misc{burneko_if_2024,
	title = {If {Kevin} {Roose} {Was} {ChatGPT} {With} {A} {Spray}-{On} {Beard}, {Could} {Anyone} {Tell}? {\textbar} {Defector}},
	shorttitle = {If {Kevin} {Roose} {Was} {ChatGPT} {With} {A} {Spray}-{On} {Beard}, {Could} {Anyone} {Tell}?},
	url = {https://defector.com/if-kevin-roose-was-chatgpt-with-a-spray-on-beard-could-anyone-tell},
	abstract = {Where do you even start with this shit: The most telling detail of Monday’s demo, in my view, was the way that OpenAI’s own employees have started talking to ChatGPT. They anthropomorphize it relentlessly, and treat it with deference—often asking “Hey ChatGPT, how’s it going?” before peppering it with questions. They cheer when it nails […]},
	language = {en},
	urldate = {2024-05-19},
	journal = {Defector},
	author = {Burneko, Albert},
	month = may,
	year = {2024},
	file = {Snapshot:C\:\\Antonio\\Zotero\\storage\\3G6MIMWX\\if-kevin-roose-was-chatgpt-with-a-spray-on-beard-could-anyone-tell.html:text/html},
}


@article{corfield_russia_2023,
	title = {Russia launches {Wikipedia} rival in new censorship crackdown},
	issn = {0307-1235},
	url = {https://www.telegraph.co.uk/business/2023/07/12/russia-rival-wikipedia-censorship-crackdown-ruwiki/},
	abstract = {Kremlin-approved service created amid growing signs of discontent over war},
	language = {en-GB},
	urldate = {2024-05-19},
	journal = {The Telegraph},
	author = {Corfield, Gareth},
	month = jul,
	year = {2023},
	keywords = {Business, Media and Telecoms industry, Russia, Russia-Ukraine war, Standard, Vladimir Putin, Wikipedia},
	file = {Corfield - 2023 - Russia launches Wikipedia rival in new censorship .pdf:C\:\\Antonio\\Zotero\\storage\\YLKCSCM2\\Corfield - 2023 - Russia launches Wikipedia rival in new censorship .pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\8YW5BIQY\\russia-rival-wikipedia-censorship-crackdown-ruwiki.html:text/html},
}

@misc{cowen_chatgpt_2023,
	title = {{ChatGPT} {Is} {Also} an {Impressive} {Feat} of {Marketing}},
	url = {https://web.archive.org/web/20240218161940/https://www.bloomberg.com/opinion/articles/2023-05-23/chatgpt-is-also-an-impressive-feat-of-marketing},
	urldate = {2024-05-17},
	journal = {Bloomberg},
	author = {Cowen, Tyler},
	month = may,
	year = {2023},
	file = {2024 - ChatGPT Is Also an Impressive Feat of Marketing - .pdf:C\:\\Antonio\\Zotero\\storage\\P4RBQ6J3\\2024 - ChatGPT Is Also an Impressive Feat of Marketing - .pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\GMQPSQBD\\chatgpt-is-also-an-impressive-feat-of-marketing.html:text/html},
}


@misc{ibm_what_2023,
	title = {What {Are} {Large} {Language} {Models} ({LLMs})?},
	shorttitle = {What {Are} {Large} {Language} {Models} ({LLMs})?},
	url = {https://www.ibm.com/topics/large-language-models},
	abstract = {Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.},
	language = {en-us},
	urldate = {2024-05-19},
	author = {\{IBM\}},
	month = nov,
	year = {2023},
	file = { IBM - 2023 - What Are Large Language Models (LLMs).pdf:C\:\\Antonio\\Zotero\\storage\\RVXWKQ2G\\ IBM - 2023 - What Are Large Language Models (LLMs).pdf:application/pdf},
}



@misc{jankowicz_russia_2023,
	title = {Russia has launched its own version of {Wikipedia}, called {Ruwiki}, which is notably more sympathetic to {Putin}},
	url = {https://www.businessinsider.com/ruwiki-putin-friendly-version-of-wikipedia-launched-in-russia-2023-7},
	abstract = {Russian Wikipedia's longtime editor quit to set up Ruwiki, a Kremlin-friendly rival that downplays the Ukraine war and criticisms of Putin.},
	language = {en-US},
	urldate = {2024-05-19},
	journal = {Business Insider},
	author = {Jankowicz, Mia},
	month = jul,
	year = {2023},
	file = {Jankowicz - Russia has launched its own version of Wikipedia, .pdf:C\:\\Antonio\\Zotero\\storage\\4W6NFG9A\\Jankowicz - Russia has launched its own version of Wikipedia, .pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\AUWR8XXR\\ruwiki-putin-friendly-version-of-wikipedia-launched-in-russia-2023-7.html:text/html},
}

@misc{lee2022deduplicating,
      title={Deduplicating Training Data Makes Language Models Better},
      author={Katherine Lee and Daphne Ippolito and Andrew Nystrom and Chiyuan Zhang and Douglas Eck and Chris Callison-Burch and Nicholas Carlini},
      year={2022},
      eprint={2107.06499},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lock_what_2022,
	title = {What is {AI} chatbot phenomenon {ChatGPT} and could it replace humans?},
	shorttitle = {What is {AI} chatbot phenomenon {ChatGPT} and could it replace humans?},
	url = {https://web.archive.org/web/20230116100346/https://www.theguardian.com/technology/2022/dec/05/what-is-ai-chatbot-phenomenon-chatgpt-and-could-it-replace-humans},
	urldate = {2024-05-17},
	journal = {The Guardian},
	author = {Lock, Samantha},
	month = dec,
	year = {2022},
	file = {Lock - 2022 - What is AI chatbot phenomenon ChatGPT and could it.pdf:C\:\\Antonio\\Zotero\\storage\\BML5VLGK\\Lock - 2022 - What is AI chatbot phenomenon ChatGPT and could it.pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\2XX8GZVV\\what-is-ai-chatbot-phenomenon-chatgpt-and-could-it-replace-humans.html:text/html},
}


@misc{nakagawa_accelerating_2023,
	title = {Accelerating {Sustainability} with {AI}: {A} {Playbook}},
	shorttitle = {Accelerating {Sustainability} with {AI}},
	url = {https://blogs.microsoft.com/on-the-issues/2023/11/16/accelerating-sustainability-ai-playbook/},
	abstract = {At Microsoft, we believe that for our company to do well, the world also needs to do well. We are at a critical moment for environmental sustainability, and we need government leaders, businesses, and civil society working in tandem. We also need to use every tool at our disposal to aid us in this journey, including AI.},
	language = {en-US},
	urldate = {2024-05-18},
	journal = {Microsoft On the Issues},
	author = {Nakagawa, Melanie, Brad Smith},
	month = nov,
	year = {2023},
	file = {Nakagawa - 2023 - Accelerating Sustainability with AI A Playbook.pdf:C\:\\Antonio\\Zotero\\storage\\JKTKCG68\\Nakagawa - 2023 - Accelerating Sustainability with AI A Playbook.pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\9XGNUZYK\\accelerating-sustainability-ai-playbook.html:text/html},
}


@article{peng_near_duplicate_2023,
	title = {Near-{Duplicate} {Sequence} {Search} at {Scale} for {Large} {Language} {Model} {Memorization} {Evaluation}},
	volume = {1},
	url = {https://doi.org/10.1145/3589324},
	doi = {10.1145/3589324},
	abstract = {Recent studies show that large language models (LLM) unintendedly memorize part of the training data, which brings serious privacy risks. For example, it has been shown that over 1\% of tokens generated unprompted by an LLM are part of sequences in the training data. However, current studies mainly focus on the exact memorization behaviors. In this paper, we propose to evaluate how many generated texts have near-duplicates (e.g., only differ by a couple of tokens out of 100) in the training corpus. A major challenge of conducting this evaluation is the huge computation cost incurred by near-duplicate sequence searches. This is because modern LLMs are trained on larger and larger corpora with up to 1 trillion tokens. What's worse is that the number of sequences in a text is quadratic to the text length. To address this issue, we develop an efficient and scalable near-duplicate sequence search algorithm in this paper. It can find (almost) all the near-duplicate sequences of the query sequence in a large corpus with guarantees. Specifically, the algorithm generates and groups the min-hash values of all the sequences with at least t tokens (as very short near-duplicates are often irrelevant noise) in the corpus in linear time to the corpus size. We formally prove that only 2 n+1/t+1 -1 min-hash values are generated for a text with n tokens in expectation. Thus the index time and size are reasonable. When a query arrives, we find all the sequences sharing enough min-hash values with the query using inverted indexes and prefix filtering. Extensive experiments on a few large real-world LLM training corpora show that our near-duplicate sequence search algorithm is efficient and scalable.},
	number = {2},
	urldate = {2024-05-19},
	journal = {Proceedings of the ACM on Management of Data},
	author = {Peng, Zhencan and Wang, Zhizhi and Deng, Dong},
	month = jun,
	year = {2023},
	keywords = {language model memorization, large language model, near-duplicate detection, text alignment},
	pages = {179:1--179:18},
	file = {Peng et al. - 2023 - Near-Duplicate Sequence Search at Scale for Large .pdf:C\:\\Antonio\\Zotero\\storage\\B79VC8K3\\Peng et al. - 2023 - Near-Duplicate Sequence Search at Scale for Large .pdf:application/pdf},
}


@article{ripley_neural_1994,
	title = {Neural {Networks} and {Related} {Methods} for {Classification}},
	volume = {56},
	copyright = {© 1994 Royal Statistical Society},
	issn = {2517-6161},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1994.tb01990.x},
	doi = {10.1111/j.2517-6161.1994.tb01990.x},
	abstract = {Feed-forward neural networks are now widely used in classification problems, whereas non-linear methods of discrimination developed in the statistical field are much less widely known. A general framework for classification is set up within which methods from statistics, neural networks, pattern recognition and machine learning can be compared. Neural networks emerge as one of a class of flexible non-linear regression methods which can be used to classify via regression. Many interesting issues remain, including parameter estimation, the assessment of the classifiers and in algorithm development.},
	language = {en},
	number = {3},
	urldate = {2024-05-19},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Ripley, B. D.},
	year = {1994},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1994.tb01990.x},
	keywords = {classification, generalization, neural networks, non-linear discriminants, projection pursuit regression, semiparametric regression},
	pages = {409--437},
	file = {Full Text PDF:C\:\\Antonio\\Zotero\\storage\\GQQ6D8UA\\Ripley - 1994 - Neural Networks and Related Methods for Classifica.pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\I8RCLKS5\\j.2517-6161.1994.tb01990.html:text/html},
}


@article{roose_is_2024,
	chapter = {Technology},
	title = {A.{I}.’s ‘{Her}’ {Era} {Has} {Arrived}},
	issn = {0362-4331},
	url = {https://www.nytimes.com/2024/05/14/technology/ai-chatgpt-her-movie.html},
	abstract = {New chatbot technology can talk, laugh and sing like a human. What comes next is anyone’s guess.},
	language = {en-US},
	urldate = {2024-05-19},
	journal = {The New York Times},
	author = {Roose, Kevin},
	month = may,
	year = {2024},
	keywords = {Artificial Intelligence, ChatGPT, Her (Movie), OpenAI Labs, Siri Inc, Smartphones, Voice and Speech},
	file = {Snapshot:C\:\\Antonio\\Zotero\\storage\\GUYNGMA8\\ai-chatgpt-her-movie.html:text/html},
}

@misc{roose_brilliance_2023,
	title = {The {Brilliance} and {Weirdness} of {ChatGPT}},
	url = {https://web.archive.org/web/20230118134332/https://www.nytimes.com/2022/12/05/technology/chatgpt-ai-twitter.html},
	urldate = {2024-05-17},
	journal = {The New York Times},
	author = {Roose, Kevin},
	month = dec,
	year = {2023},
	file = {Roose - 2023 - The Brilliance and Weirdness of ChatGPT - The New .pdf:C\:\\Antonio\\Zotero\\storage\\Y73G4FCJ\\Roose - 2023 - The Brilliance and Weirdness of ChatGPT - The New .pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\TKTWJT9F\\chatgpt-ai-twitter.html:text/html},
}

@misc{office_of_teaching_and_learning_provisional_2023,
	title = {Provisional {Recommendations} for the {Use} of {Generative} {AI} {\textbar} {Office} of {Teaching} and {Learning}},
	url = {https://otl.uoguelph.ca/teaching-assessment-resources/teaching-context-ai/provisional-recommendations-use-generative-ai},
	urldate = {2024-05-18},
	author = {{Office of Teaching {and} Learning}, {University of Guelph}},
	year = {2023},
	file = { Office of Teaching and Learning - Provisional Recommendations for the Use of Generat.pdf:C\:\\Antonio\\Zotero\\storage\\3UXHBXNW\\ Office of Teaching and Learning - Provisional Recommendations for the Use of Generat.pdf:application/pdf;Provisional Recommendations for the Use of Generative AI | Office of Teaching and Learning:C\:\\Antonio\\Zotero\\storage\\QZDCMUT8\\provisional-recommendations-use-generative-ai.html:text/html;Trent Generative AI Guidelines _ T&L Approved _ Dec 2023.pdf:C\:\\Antonio\\Zotero\\storage\\BFBNQR55\\Trent Generative AI Guidelines _ T&L Approved _ Dec 2023.pdf:application/pdf},
}


@misc{smith_our_2024,
	title = {Our 2024 {Environmental} {Sustainability} {Report}},
	url = {https://blogs.microsoft.com/on-the-issues/2024/05/15/microsoft-environmental-sustainability-report-2024/},
	abstract = {Today, Microsoft published the 2024 Environmental Sustainability Report. This report covers fiscal year 2023, and measures progress against our 2020 baseline.},
	language = {en-US},
	urldate = {2024-05-18},
	journal = {Microsoft On the Issues},
	author = {Smith, Brad and Nagagawa, Melanie},
	month = may,
	year = {2024},
	file = {Smith and Nagagawa - 2024 - Our 2024 Environmental Sustainability Report.pdf:C\:\\Antonio\\Zotero\\storage\\86YW7WVC\\Smith and Nagagawa - 2024 - Our 2024 Environmental Sustainability Report.pdf:application/pdf;Snapshot:C\:\\Antonio\\Zotero\\storage\\J4NZFDAD\\microsoft-environmental-sustainability-report-2024.html:text/html},
}


@misc{trent_university_generative_2024,
	title = {Generative {Artificial} {Intelligence}, {Trent} {University} {Guidelines}, 2024},
	url = {https://otl.uoguelph.ca/teaching-assessment-resources/teaching-context-ai/provisional-recommendations-use-generative-ai},
	urldate = {2024-05-18},
	author = {{Trent University}},
	year = {2024},
}



@misc{hiskes_woodward_2007,
	title = {Woodward: ‘{Journalism} is not stenography’},
	shorttitle = {Woodward},
	url = {https://mediaschool.indiana.edu/news-events/news/item.html?n=woodward-journalism-is-not-stenography/},
	language = {en-US},
	urldate = {2024-05-19},
	journal = {The Media School Indiana University Bloomington},
	author = {Hiskes, Jonathan},
	year = {2007},
	file = {Snapshot:C\:\\Antonio\\Zotero\\storage\\ZXRGFMV3\\item.html:text/html},
}
